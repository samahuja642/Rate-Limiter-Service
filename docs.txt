ğŸ“Œ Rate Limiter Service â€” Requirements
1ï¸âƒ£ Functional Requirements (MUST HAVE)
1.1 Request Limiting

The system must limit incoming API requests based on a defined quota.

Default limit: 100 requests per minute.

1.2 Identification Strategy

Requests should be rate-limited by:

IP address (default)

User ID (if provided in headers)

Priority:

If X-User-Id header exists â†’ use User ID

Else â†’ fallback to IP address

1.3 Rate Limiting Algorithm

Use Token Bucket Algorithm.

Each identifier maintains:

Token count

Last refill timestamp

Tokens refill continuously over time.

1.4 Distributed State

Rate limiting state must be stored in Redis.

The system should support multiple API instances sharing the same rate limit state.

1.5 Middleware-Based Enforcement

Rate limiting should be implemented as middleware.

All protected routes must pass through the rate limiter.

1.6 HTTP Responses

Allowed requests:

Proceed normally (200 OK)

Blocked requests:

Respond with 429 Too Many Requests

Response body should include an error message

2ï¸âƒ£ HTTP Headers (IMPORTANT)

For every response (allowed or blocked):

X-RateLimit-Limit: 100
X-RateLimit-Remaining: <remaining_tokens>


For blocked requests only:

Retry-After: <seconds_until_next_token>

3ï¸âƒ£ Non-Functional Requirements
3.1 Performance

Rate limiter must handle high concurrency.

Redis operations should be O(1) per request.

3.2 Atomicity & Consistency

Token refill and consumption must be logically atomic.

In a real production setup:

Logic should be moved to a Redis Lua script (documented as future improvement).

3.3 Fault Tolerance

If Redis is unavailable:

Fail open (allow request) OR fail closed (block request).

Chosen strategy must be explicitly documented.

3.4 Configurability

Rate limit values should be configurable via:

Environment variables

Code-level defaults

4ï¸âƒ£ API Endpoints
4.1 Protected Endpoint
GET /api/test


Subject to rate limiting

Returns a simple success response

4.2 Health Check
GET /health


Verifies application and Redis connectivity

Not rate-limited

5ï¸âƒ£ Error Handling

Invalid or missing headers should not break the system.

Redis errors must be:

Logged

Handled gracefully based on fail strategy

6ï¸âƒ£ Logging & Observability (Nice to Have)

Log blocked requests with:

Identifier

Timestamp

Remaining tokens

Include request latency logging (optional)

7ï¸âƒ£ Security Considerations

Headers must not be trusted blindly.

User-based rate limiting should be used only after authentication (document assumption).

8ï¸âƒ£ Documentation Requirements (VERY IMPORTANT)

README must include:

Architecture overview

Rate limiting algorithm explanation

Redis data model

Trade-offs made

Scaling considerations

Future improvements

9ï¸âƒ£ Out of Scope (Explicitly State This)

Authentication system

UI-heavy frontend

Persistent analytics storage

Multi-region Redis replication


Level 1 â€” Correctness & hygiene (quick wins)

Do these before changing algorithms.

â˜ Extract limiter logic from middleware (pure function / class)

â˜ Handle window reset cleanly

â˜ Prevent race conditions (atomic increments or locking)

â˜ Add config (limit, window size)

â˜ Return proper 429 responses

Outcome: clean, testable, predictable behavior.

Level 2 â€” Time & boundary behavior

This is where most bugs live.

â˜ Handle exact boundary cases (limit, limit+1)

â˜ Decide inclusive vs exclusive limits

â˜ Use monotonic time (avoid Date.now() pitfalls)

â˜ Test with fake timers

Outcome: you understand why rate limiters misbehave in production.

Level 3 â€” Algorithm upgrade â­

Pick one (donâ€™t do all at once).

Option A: Sliding Window Counter

â˜ Weight previous window

â˜ Tune accuracy vs cost

Option B: Token Bucket (recommended)

â˜ Implement refill logic

â˜ Allow controlled bursts

â˜ Handle precision issues

Outcome: real-world, interview-relevant knowledge.

Level 4 â€” Distributed support (Redis)

Only do this after Level 3.

â˜ Move counters to Redis

â˜ Use atomic operations or Lua

â˜ Set TTL correctly

â˜ Handle Redis failures (fail-open vs fail-closed)

Outcome: you now understand distributed rate limiting tradeoffs.

Level 5 â€” API & client experience (often skipped)

Small effort, big signal.

â˜ Add response headers:

Retry-After

X-RateLimit-Limit

X-RateLimit-Remaining

â˜ Different limits per route / user

â˜ Clear error messages

Outcome: production-grade behavior.

Level 6 â€” Observability & safety

Donâ€™t over-engineer â€” just basics.

â˜ Metrics: allowed vs blocked

â˜ Log sampled limit hits

â˜ Protect against memory leaks (key cleanup)

â˜ Guard against hot keys

Outcome: operational awareness.

Level 7 â€” Resilience & tuning (advanced, optional)

Only if you want depth.

â˜ Graceful degradation

â˜ Burst tuning

â˜ Soft vs hard limits

â˜ Shadow mode (monitor without blocking)

Outcome: senior-level thinking.